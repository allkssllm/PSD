{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b21e52c",
   "metadata": {},
   "source": [
    "# Forecasting dengan AutoKorelasi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083cc136",
   "metadata": {},
   "source": [
    "## DataUnderstanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce609bfb",
   "metadata": {},
   "source": [
    "### Import Library  \n",
    "Kode ini berfungsi untuk mengimpor semua library Python yang diperlukan untuk analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33fb8dca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openeo'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopeneo\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openeo'"
     ]
    }
   ],
   "source": [
    "import openeo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fe5d0f",
   "metadata": {},
   "source": [
    "### Koneksi ke Server  \n",
    "Cell ini digunakan untuk membangun koneksi ke backend openeo dan melakukan otentikasi menggunakan protokol OIDC. Langkah ini diperlukan untuk mendapatkan akses resmi ke koleksi data yang tersedia di server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7ae0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    }
   ],
   "source": [
    "# Connect to openEO backend\n",
    "connection = openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086155f1",
   "metadata": {},
   "source": [
    "### Penentuan Area dan Rentang Waktu  \n",
    "Blok kode ini mendefinisikan parameter spasial (spatial extent) dan temporal (temporal extent) untuk akuisisi data. spatial_extent menentukan batas geografis area penelitian (Surabaya), sedangkan start_date dan end_date membatasi rentang waktu data yang akan diunduh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18a08f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AOI defined for coordinates: {'west': 112.73333744680662, 'south': -7.240796541868804, 'east': 112.76429592850928, 'north': -7.213897744108465}\n",
      " Time range: 2020-10-23 to 2025-10-23\n",
      " Setup completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Area of Interest (AOI) - versi kamu\n",
    "aoi = {\n",
    "  \"type\": \"FeatureCollection\",\n",
    "  \"features\": [\n",
    "    {\n",
    "      \"type\": \"Feature\",\n",
    "      \"properties\": {},\n",
    "      \"geometry\": {\n",
    "        \"coordinates\": [\n",
    "          [\n",
    "            [\n",
    "              112.73333744680662,\n",
    "              -7.213897744108465\n",
    "            ],\n",
    "            [\n",
    "              112.73333744680662,\n",
    "              -7.240796541868804\n",
    "            ],\n",
    "            [\n",
    "              112.76429592850928,\n",
    "              -7.240796541868804\n",
    "            ],\n",
    "            [\n",
    "              112.76429592850928,\n",
    "              -7.213897744108465\n",
    "            ],\n",
    "            [\n",
    "              112.73333744680662,\n",
    "              -7.213897744108465\n",
    "            ]\n",
    "          ]\n",
    "        ],\n",
    "        \"type\": \"Polygon\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Define spatial extent from AOI coordinates (disesuaikan juga)\n",
    "spatial_extent = {\n",
    "    \"west\": 112.73333744680662,\n",
    "    \"south\": -7.240796541868804,\n",
    "    \"east\": 112.76429592850928,\n",
    "    \"north\": -7.213897744108465\n",
    "}\n",
    "\n",
    "# Rentang waktu (kamu bisa ubah sesuai kebutuhan)\n",
    "start_date = \"2020-10-23\"\n",
    "end_date = \"2025-10-23\"\n",
    "\n",
    "print(f\" AOI defined for coordinates: {spatial_extent}\")\n",
    "print(f\" Time range: {start_date} to {end_date}\")\n",
    "print(\" Setup completed successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d369f1",
   "metadata": {},
   "source": [
    "![tampilanMiniforge1](./images/kordinat.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd416fd",
   "metadata": {},
   "source": [
    "### Pengambilan dan Agregasi Data\n",
    "Kode ini menginstruksikan server untuk memuat koleksi data polusi NO2 dari satelit Sentinel-5P sesuai parameter yang telah ditentukan. Fungsi aggregate_temporal_period digunakan untuk merata-ratakan data harian menjadi satu nilai tunggal per hari (period=\"day\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64193888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sentinel-5P NO2 data...\n",
      "Data collection and aggregation configured successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Sentinel-5P NO2 data...\")\n",
    "\n",
    "s5p_no2 = connection.load_collection(\n",
    "    \"SENTINEL_5P_L2\",\n",
    "    temporal_extent=[start_date, end_date],\n",
    "    spatial_extent=spatial_extent,\n",
    "    bands=[\"NO2\"],\n",
    ")\n",
    "\n",
    "s5p_monthly = s5p_no2.aggregate_temporal_period(\n",
    "    period=\"day\",\n",
    "    reducer=\"mean\"\n",
    ")\n",
    "\n",
    "print(\"Data collection and aggregation configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b47cc2",
   "metadata": {},
   "source": [
    "### Eksekusi Proses dan Pengunduhan\n",
    "Fungsi execute_batch memulai proses pengumpulan dan agregasi data di sisi server secara asynchronous. Hasil dari proses ini akan disimpan dalam sebuah file output dengan format NetCDF (.nc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0a6e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data processing job...\n",
      "0:00:00 Job 'j-25102316381049339dfcf6a3c1e3061a': send 'start'\n",
      "0:00:30 Job 'j-25102316381049339dfcf6a3c1e3061a': created (progress 0%)\n",
      "0:00:36 Job 'j-25102316381049339dfcf6a3c1e3061a': created (progress 0%)\n",
      "0:00:43 Job 'j-25102316381049339dfcf6a3c1e3061a': created (progress 0%)\n",
      "0:00:52 Job 'j-25102316381049339dfcf6a3c1e3061a': created (progress 0%)\n",
      "0:01:03 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:01:16 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:01:32 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:01:52 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:02:19 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:02:50 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:03:30 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:04:18 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:05:17 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:06:18 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:07:20 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:08:21 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:09:22 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:10:25 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:11:25 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:12:26 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:13:27 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:14:27 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:15:29 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:16:29 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:17:29 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:18:30 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:19:31 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:20:31 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:21:32 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:22:33 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:23:34 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:24:35 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:25:36 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:26:36 Job 'j-25102316381049339dfcf6a3c1e3061a': running (progress N/A)\n",
      "0:27:40 Job 'j-25102316381049339dfcf6a3c1e3061a': finished (progress 100%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting data processing job...\")\n",
    "\n",
    "job = s5p_monthly.execute_batch(\n",
    "    title=\"NO2 Averages 2020-2025\", \n",
    "    outputfile=\"no2_averages_4years.nc\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c880f65c",
   "metadata": {},
   "source": [
    "### Konversi dari Format .nc ke .csv\n",
    "Cell ini berfungsi untuk membaca file .nc yang telah diunduh menggunakan xarray, kemudian mengonversinya ke dalam format DataFrame pandas. Hasilnya diekspor menjadi file hasil-data.csv untuk pengolahan lebih lanjut yang lebih mudah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c381e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selesai! File 'hasil-data.csv' telah dibuat.\n"
     ]
    }
   ],
   "source": [
    "# 1. Buka file .nc Anda\n",
    "# Ganti 'openEO.nc' jika nama filenya berbeda\n",
    "ds = xr.open_dataset(\"D:\\VSCode1\\MatKul-psd\\PSD\\MataKuliah-Psd\\dataset\\openEO.nc\", engine=\"h5netcdf\")\n",
    "\n",
    "# 2. Konversi dataset xarray menjadi DataFrame pandas\n",
    "df = ds.to_dataframe()\n",
    "\n",
    "# 3. [PENTING] Ratakan Multi-Index\n",
    "# Data NetCDF biasanya punya banyak index (spt waktu, lat, lon).\n",
    "# 'reset_index()' akan mengubah semua index itu menjadi kolom biasa.\n",
    "df_flat = df.reset_index()\n",
    "\n",
    "# 4. Simpan sebagai file CSV\n",
    "df_flat.to_csv('dataset/hasil-data.csv', index=False)\n",
    "\n",
    "print(\"Selesai! File 'hasil-data.csv' telah dibuat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b693e25a",
   "metadata": {},
   "source": [
    "## DataPreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2101014d",
   "metadata": {},
   "source": [
    "### Pengurutan Data Berdasarkan Waktu\n",
    "Kode ini melakukan pengurutan data secara kronologis berdasarkan kolom waktu ('t'). Ini adalah langkah preprocessing yang fundamental untuk data time-series guna memastikan urutan observasi sudah benar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c6e834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              t           x         y  crs       NO2\n",
      "0    2020-10-23  112.760619 -7.223435  b''       NaN\n",
      "1    2020-10-24  112.760619 -7.223435  b''  0.000034\n",
      "2    2020-10-25  112.760619 -7.223435  b''  0.000012\n",
      "3    2020-10-26  112.760619 -7.223435  b''       NaN\n",
      "4    2020-10-27  112.760619 -7.223435  b''  0.000141\n",
      "...         ...         ...       ...  ...       ...\n",
      "1800 2025-10-18  112.760619 -7.223435  b''  0.000026\n",
      "1801 2025-10-19  112.760619 -7.223435  b''       NaN\n",
      "1802 2025-10-20  112.760619 -7.223435  b''       NaN\n",
      "1803 2025-10-21  112.760619 -7.223435  b''       NaN\n",
      "1804 2025-10-22  112.760619 -7.223435  b''       NaN\n",
      "\n",
      "[1805 rows x 5 columns]\n",
      "Selesai! Data telah diurutkan berdasarkan waktu dan disimpan di './dataset/hasil-data-sorted.csv'\n"
     ]
    }
   ],
   "source": [
    "# 1. Baca file CSV\n",
    "df = pd.read_csv('./dataset/hasil-data.csv')\n",
    "\n",
    "# 2. Ubah kolom 't' menjadi format datetime\n",
    "df['t'] = pd.to_datetime(df['t'])\n",
    "\n",
    "# 3. Urutkan DataFrame berdasarkan kolom 't'\n",
    "df_sorted = df.sort_values(by='t')\n",
    "\n",
    "# 4. Menampilkan hasil pengirutan\n",
    "print(df_sorted)\n",
    "\n",
    "print(\"Selesai! Data telah diurutkan berdasarkan waktu dan disimpan di './dataset/hasil-data-sorted.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d77c5",
   "metadata": {},
   "source": [
    "### Interpolasi untuk Mengisi Data Hilang\n",
    "Langkah ini bertujuan untuk menangani nilai yang hilang (NaN) dalam data. Metode interpolasi berbasis waktu (method='time') digunakan untuk mengisi kekosongan data dengan memperkirakan nilainya berdasarkan interval waktu antara titik data yang valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2432b31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selesai! Data sudah diinterpolasi dan disimpan dalam variabel 'df_interpolated'.\n",
      "\n",
      "Cuplikan 5 baris pertama dari data hasil interpolasi:\n",
      "           t           x         y  crs       NO2\n",
      "0 2020-10-23  112.760619 -7.223435  b''       NaN\n",
      "1 2020-10-24  112.760619 -7.223435  b''  0.000034\n",
      "2 2020-10-25  112.760619 -7.223435  b''  0.000012\n",
      "3 2020-10-26  112.760619 -7.223435  b''  0.000076\n",
      "4 2020-10-27  112.760619 -7.223435  b''  0.000141\n",
      "\n",
      "Sisa missing values di kolom 'NO2': 1\n"
     ]
    }
   ],
   "source": [
    "df_indexed = df_sorted.set_index('t')\n",
    "\n",
    "# 5. Lakukan interpolasi pada kolom 'NO2'\n",
    "df_indexed['NO2'] = df_indexed['NO2'].interpolate(method='time')\n",
    "\n",
    "# 6. Kembalikan 't' menjadi kolom & simpan di variabel baru\n",
    "df_interpolated = df_indexed.reset_index()\n",
    "\n",
    "\n",
    "# --- Konfirmasi Hasil ---\n",
    "print(\"Selesai! Data sudah diinterpolasi dan disimpan dalam variabel 'df_interpolated'.\")\n",
    "print(\"\\nCuplikan 5 baris pertama dari data hasil interpolasi:\")\n",
    "print(df_interpolated.head())\n",
    "print(f\"\\nSisa missing values di kolom 'NO2': {df_interpolated['NO2'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b0d780f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data diinterpolasi. Jumlah baris: 1805\n"
     ]
    }
   ],
   "source": [
    "df['t'] = pd.to_datetime(df['t'])\n",
    "df_sorted = df.sort_values(by='t')\n",
    "df_indexed = df_sorted.set_index('t')\n",
    "df_indexed['NO2'] = df_indexed['NO2'].interpolate(method='time')\n",
    "df_interpolated = df_indexed.reset_index()\n",
    "print(f\"Data diinterpolasi. Jumlah baris: {len(df_interpolated)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22338c7",
   "metadata": {},
   "source": [
    "#### Analisis Nilai Outlier pada Data NO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "576685e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selesai! Ditemukan 69 nilai outlier pada data NO2.\n",
      "Selesai! Nilai outlier telah diimputasi dengan median NO2.\n"
     ]
    }
   ],
   "source": [
    "no2_values = df_interpolated['NO2']\n",
    "q1 = no2_values.quantile(0.25)\n",
    "q3 = no2_values.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "outliers = df_interpolated[(no2_values < lower_bound) | (no2_values > upper_bound)]\n",
    "\n",
    "# --- Konfirmasi Hasil ---\n",
    "print(f\"Selesai! Ditemukan {len(outliers)} nilai outlier pada data NO2.\")\n",
    "# Imputasi Nilai Outlier dengan Metode Median\n",
    "df_no_outliers = df_interpolated.copy()\n",
    "median_no2 = df_no_outliers['NO2'].median()\n",
    "df_no_outliers.loc[(df_no_outliers['NO2'] < lower_bound) | (df_no_outliers['NO2'] > upper_bound), 'NO2'] = median_no2\n",
    "print(\"Selesai! Nilai outlier telah diimputasi dengan median NO2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66095d25",
   "metadata": {},
   "source": [
    "#### Ubah data time series ke data supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a10be38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selesai! DataFrame 'df_supervised' telah dibuat dengan 3 lag features.\n",
      "\n",
      "Cuplikan 5 baris pertama dari data supervised:\n",
      "           t  NO2_target(t)  NO2(t-1)  NO2(t-2)  NO2(t-3)\n",
      "0 2020-10-27       0.000141  0.000076  0.000012  0.000034\n",
      "1 2020-10-28       0.000021  0.000141  0.000076  0.000012\n",
      "2 2020-10-29       0.000027  0.000021  0.000141  0.000076\n",
      "3 2020-10-30       0.000033  0.000027  0.000021  0.000141\n",
      "4 2020-10-31       0.000039  0.000033  0.000027  0.000021\n"
     ]
    }
   ],
   "source": [
    "# Mulai dengan DataFrame 'df_interpolated' dari langkah sebelumnya\n",
    "# 1. Pilih hanya kolom waktu ('t') dan nilai ('NO2')\n",
    "data = df_interpolated[['t', 'NO2']].copy()\n",
    "\n",
    "# 2. Tentukan berapa banyak lag yang ingin Anda buat (misalnya: 3 hari sebelumnya)\n",
    "N_LAGS = 3\n",
    "\n",
    "# 3. Buat fitur lag (geser data ke bawah)\n",
    "for i in range(1, N_LAGS + 1):\n",
    "    data[f'NO2(t-{i})'] = data['NO2'].shift(i)\n",
    "\n",
    "# 4. Ganti nama kolom 'NO2' asli menjadi target (y)\n",
    "data.rename(columns={'NO2': 'NO2_target(t)'}, inplace=True)\n",
    "\n",
    "# 5. Hapus baris yang mengandung NaN\n",
    "# Ini adalah N_LAGS baris pertama, yang tidak memiliki data historis\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# 6. Reset index agar rapi\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 7. Simpan hasil akhir ke variabel baru 'df_supervised'\n",
    "df_supervised = data\n",
    "\n",
    "# 8. Tampilkan hasilnya\n",
    "print(f\"Selesai! DataFrame 'df_supervised' telah dibuat dengan {N_LAGS} lag features.\")\n",
    "print(\"\\nCuplikan 5 baris pertama dari data supervised:\")\n",
    "print(df_supervised.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5e1f3",
   "metadata": {},
   "source": [
    "#### AutoKorelasi & Seleksi Fitur\n",
    "Cell ini menganalisis korelasi antara semua fitur lag (t-1 s/d t-14) dengan nilai target (t).\n",
    "Fitur yang memiliki korelasi absolut di atas 0.5 akan dipilih untuk pemodelan.\n",
    "Ini membantu mengurangi dimensi data dan hanya menggunakan fitur yang paling relevan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cf1cee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memulai Autokorelasi untuk Seleksi Fitur...\n",
      "Fitur lag terpilih (korelasi > 0.5): ['NO2(t-1)', 'NO2(t-2)', 'NO2(t-3)']\n",
      "Kolom yang tidak terpilih telah di-drop.\n",
      "\n",
      "Cuplikan 5 baris pertama dari df_supervised (setelah seleksi fitur):\n",
      "           t  NO2(t-1)  NO2(t-2)  NO2(t-3)  NO2_target(t)\n",
      "0 2020-11-07  0.000020  0.000025  0.000030       0.000032\n",
      "1 2020-11-08  0.000032  0.000020  0.000025       0.000030\n",
      "2 2020-11-09  0.000030  0.000032  0.000020       0.000030\n",
      "3 2020-11-10  0.000030  0.000030  0.000032       0.000026\n",
      "4 2020-11-11  0.000026  0.000030  0.000030       0.000024\n"
     ]
    }
   ],
   "source": [
    "# Mulai dengan DataFrame 'df_interpolated' dari langkah sebelumnya\n",
    "data = df_interpolated[['t', 'NO2']].copy()\n",
    "# Tentukan berapa banyak lag yang ingin Anda buat (misalnya: 14 hari)\n",
    "N_LAGS_MAX = 14 \n",
    "# Buat fitur lag (geser data ke bawah)\n",
    "for i in range(1, N_LAGS_MAX + 1):\n",
    "    data[f'NO2(t-{i})'] = data['NO2'].shift(i)\n",
    "# Ganti nama kolom 'NO2' asli menjadi target (y)\n",
    "data.rename(columns={'NO2': 'NO2_target(t)'}, inplace=True)\n",
    "# Hapus baris yang mengandung NaN\n",
    "data.dropna(inplace=True)\n",
    "# Reset index agar rapi\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "# Simpan hasil akhir ke variabel baru 'df_supervised_full'\n",
    "df_supervised_full = data\n",
    "print(\"\\nMemulai Autokorelasi untuk Seleksi Fitur...\")\n",
    "# 1. Hitung matriks korelasi\n",
    "corr_matrix = df_supervised_full.corr(numeric_only=True)\n",
    "# 2. Ambil korelasi semua fitur dengan target\n",
    "corr_target = corr_matrix['NO2_target(t)']\n",
    "# 3. Pilih fitur lag yang memiliki korelasi absolut > 0.5\n",
    "feature_cols = corr_target[(np.abs(corr_target) > 0.5) & (corr_target.index.str.startswith('NO2(t-'))].index.tolist()\n",
    "print(f\"Fitur lag terpilih (korelasi > 0.5): {feature_cols}\")\n",
    "# 4. Fallback jika tidak ada fitur yang lolos seleksi\n",
    "if not feature_cols:\n",
    "    print(\"PERINGATAN: Tidak ada fitur lag > 0.5. Menggunakan lag t-1 sebagai default.\")\n",
    "    feature_cols = ['NO2(t-1)'] # Fallback\n",
    "# 5. Siapkan daftar kolom final untuk df_supervised\n",
    "target_col = ['NO2_target(t)']\n",
    "all_selected_cols = ['t'] + feature_cols + target_col\n",
    "# 6. Buat DataFrame df_supervised yang baru HANYA dengan fitur terpilih\n",
    "df_supervised = df_supervised_full[all_selected_cols].copy()\n",
    "print(f\"Kolom yang tidak terpilih telah di-drop.\")\n",
    "print(\"\\nCuplikan 5 baris pertama dari df_supervised (setelah seleksi fitur):\")\n",
    "print(df_supervised.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafed49e",
   "metadata": {},
   "source": [
    "### Normalisasi Data (Z-Score)\n",
    "Normalisasi data dilakukan menggunakan StandardScaler (Z-score). Tujuannya adalah untuk mengubah skala semua fitur sehingga memiliki rata-rata 0 dan standar deviasi 1. Ini penting untuk meningkatkan performa model K-NN yang sensitif terhadap skala data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "106df1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           t  NO2(t-1)  NO2(t-2)  NO2(t-3)  NO2_target(t)\n",
      "0 2020-11-07 -0.906693 -0.747785 -0.589003      -0.543413\n",
      "1 2020-11-08 -0.543274 -0.906681 -0.747907      -0.593825\n",
      "2 2020-11-09 -0.593682 -0.543263 -0.906811      -0.600431\n",
      "3 2020-11-10 -0.600288 -0.593671 -0.543374      -0.712232\n",
      "4 2020-11-11 -0.712079 -0.600277 -0.593785      -0.787335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pisahkan kolom fitur (X) dan target (y)\n",
    "features_cols = [col for col in df_supervised.columns if col.startswith('NO2(t-')]\n",
    "target_col = ['NO2_target(t)']\n",
    "\n",
    "# Buat scaler terpisah untuk fitur dan target\n",
    "feature_scaler_z = StandardScaler()\n",
    "target_scaler_z = StandardScaler()\n",
    "\n",
    "# Buat salinan DataFrame\n",
    "df_scaled_z = df_supervised.copy()\n",
    "\n",
    "# Fit dan transform fitur\n",
    "df_scaled_z[features_cols] = feature_scaler_z.fit_transform(df_scaled_z[features_cols])\n",
    "# Fit dan transform target\n",
    "df_scaled_z[target_col] = target_scaler_z.fit_transform(df_scaled_z[target_col])\n",
    "\n",
    "print(df_scaled_z.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e07f81",
   "metadata": {},
   "source": [
    "## Model K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8ea858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9e4151",
   "metadata": {},
   "source": [
    "#### Explorasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db65ff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Informasi Tipe Data & Non-Null ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1790 entries, 0 to 1789\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   t              1790 non-null   datetime64[ns]\n",
      " 1   NO2(t-1)       1790 non-null   float64       \n",
      " 2   NO2(t-2)       1790 non-null   float64       \n",
      " 3   NO2(t-3)       1790 non-null   float64       \n",
      " 4   NO2_target(t)  1790 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(4)\n",
      "memory usage: 70.1 KB\n",
      "\n",
      "--- 2. Deskripsi Statistik ---\n",
      "                                   t      NO2(t-1)      NO2(t-2)  \\\n",
      "count                           1790  1.790000e+03  1.790000e+03   \n",
      "mean   2023-05-04 17:27:25.139664896  7.145122e-17 -7.939025e-18   \n",
      "min              2020-11-07 00:00:00 -1.296698e+00 -1.296683e+00   \n",
      "25%              2022-02-08 06:00:00 -6.985697e-01 -6.985584e-01   \n",
      "50%              2023-05-05 12:00:00 -3.206834e-01 -3.206742e-01   \n",
      "75%              2024-07-28 18:00:00  4.923875e-01  4.923922e-01   \n",
      "max              2025-10-22 00:00:00  4.066846e+00  4.066831e+00   \n",
      "std                              NaN  1.000279e+00  1.000279e+00   \n",
      "\n",
      "           NO2(t-3)  NO2_target(t)  \n",
      "count  1.790000e+03   1.790000e+03  \n",
      "mean   2.699268e-16   1.032073e-16  \n",
      "min   -1.296834e+00  -1.296896e+00  \n",
      "25%   -6.967333e-01  -6.987211e-01  \n",
      "50%   -3.207728e-01  -3.208049e-01  \n",
      "75%    4.923374e-01   4.923302e-01  \n",
      "max    4.066969e+00   4.067071e+00  \n",
      "std    1.000279e+00   1.000279e+00  \n",
      "\n",
      "--- 3. Pengecekan Missing Values ---\n",
      "t                0\n",
      "NO2(t-1)         0\n",
      "NO2(t-2)         0\n",
      "NO2(t-3)         0\n",
      "NO2_target(t)    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. Informasi Tipe Data & Non-Null ---\")\n",
    "# .info() akan mencetak ringkasan DataFrame\n",
    "df_scaled_z.info()\n",
    "print(\"\\n--- 2. Deskripsi Statistik ---\")\n",
    "# .describe() akan memberikan statistik deskriptif\n",
    "print(df_scaled_z.describe())\n",
    "\n",
    "print(\"\\n--- 3. Pengecekan Missing Values ---\")\n",
    "# .isna().sum() akan menghitung jumlah nilai NaN di setiap kolom\n",
    "print(df_scaled_z.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d0f51c",
   "metadata": {},
   "source": [
    "#### Persiapan Data untuk Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31937993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Variabel Fitur (X) ---\n",
      "Kolom yang digunakan: ['NO2(t-1)', 'NO2(t-2)', 'NO2(t-3)']\n",
      "   NO2(t-1)  NO2(t-2)  NO2(t-3)\n",
      "0 -0.906693 -0.747785 -0.589003\n",
      "1 -0.543274 -0.906681 -0.747907\n",
      "2 -0.593682 -0.543263 -0.906811\n",
      "3 -0.600288 -0.593671 -0.543374\n",
      "4 -0.712079 -0.600277 -0.593785\n",
      "\n",
      "--- Variabel Target (y) ---\n",
      "Kolom yang digunakan: NO2_target(t)\n",
      "0   -0.543413\n",
      "1   -0.593825\n",
      "2   -0.600431\n",
      "3   -0.712232\n",
      "4   -0.787335\n",
      "Name: NO2_target(t), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Kita menggunakan DataFrame 'df_scaled_z' (hasil Z-Score)\n",
    "\n",
    "# 1. Identifikasi Kolom Fitur (X)\n",
    "# Ini adalah variabel prediktor (data historis)\n",
    "feature_columns = [col for col in df_scaled_z.columns if col.startswith('NO2(t-')]\n",
    "\n",
    "# 2. Identifikasi Kolom Target (y)\n",
    "# Ini adalah variabel yang ingin diprediksi (data saat ini)\n",
    "target_column = 'NO2_target(t)'\n",
    "\n",
    "# 3. Buat variabel X dan y\n",
    "# X (biasanya huruf besar) adalah DataFrame yang berisi semua fitur\n",
    "X = df_scaled_z[feature_columns]\n",
    "\n",
    "# y (biasanya huruf kecil) adalah Series yang berisi target\n",
    "y = df_scaled_z[target_column]\n",
    "\n",
    "# 4. Tampilkan konfirmasi\n",
    "print(\"--- Variabel Fitur (X) ---\")\n",
    "print(f\"Kolom yang digunakan: {feature_columns}\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\n--- Variabel Target (y) ---\")\n",
    "print(f\"Kolom yang digunakan: {target_column}\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1428d",
   "metadata": {},
   "source": [
    "#### Bagi data Training dan Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac7c8a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 1790 baris\n",
      "Jumlah data Latih (Train): 1432 baris (80%)\n",
      "Jumlah data Uji (Test): 358 baris (20%)\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan X dan y dari langkah sebelumnya\n",
    "train_size = int(len(X) * 0.8)\n",
    "\n",
    "# 2. Bagi data X (fitur)\n",
    "X_train = X.iloc[0:train_size]\n",
    "X_test = X.iloc[train_size:len(X)]\n",
    "\n",
    "# 3. Bagi data y (target)\n",
    "y_train = y.iloc[0:train_size]\n",
    "y_test = y.iloc[train_size:len(y)]\n",
    "\n",
    "t_test = df_supervised['t'].iloc[train_size:len(df_supervised)]\n",
    "\n",
    "# 4. Tampilkan konfirmasi\n",
    "print(f\"Total data: {len(X)} baris\")\n",
    "print(f\"Jumlah data Latih (Train): {len(X_train)} baris (80%)\")\n",
    "print(f\"Jumlah data Uji (Test): {len(X_test)} baris (20%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc1a710",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning (Mencari K Optimal)\n",
    "\n",
    "Tahap ini melakukan iterasi untuk melatih dan mengevaluasi model K-NN dengan nilai 'K' yang berbeda (dari 1 hingga 30). Tujuannya adalah untuk menemukan nilai `best_k` (K optimal) yang menghasilkan RMSE terendah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5feb1b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memulai pencarian K optimal...\n",
      "k = 1, RMSE = 2.9298093726231992e-05\n",
      "k = 2, RMSE = 2.1447579321554876e-05\n",
      "k = 3, RMSE = 1.9441514891001982e-05\n",
      "k = 4, RMSE = 1.8441144625944083e-05\n",
      "k = 5, RMSE = 1.7533753994127963e-05\n",
      "k = 6, RMSE = 1.6941059456630807e-05\n",
      "k = 7, RMSE = 1.667804526955685e-05\n",
      "k = 8, RMSE = 1.6435042535842854e-05\n",
      "k = 9, RMSE = 1.6124034776027293e-05\n",
      "k = 10, RMSE = 1.6258894822818882e-05\n",
      "k = 11, RMSE = 1.5888261535517677e-05\n",
      "k = 12, RMSE = 1.5884740689992907e-05\n",
      "k = 13, RMSE = 1.5897922362492306e-05\n",
      "k = 14, RMSE = 1.5851948601153985e-05\n",
      "k = 15, RMSE = 1.5688005393794294e-05\n",
      "k = 16, RMSE = 1.566383918986877e-05\n",
      "k = 17, RMSE = 1.5506889948284097e-05\n",
      "k = 18, RMSE = 1.5435961595274344e-05\n",
      "k = 19, RMSE = 1.535753593705555e-05\n",
      "k = 20, RMSE = 1.527293189243738e-05\n",
      "k = 21, RMSE = 1.5222436641719718e-05\n",
      "k = 22, RMSE = 1.531884910982575e-05\n",
      "k = 23, RMSE = 1.5365719855578842e-05\n",
      "k = 24, RMSE = 1.5360798304990498e-05\n",
      "k = 25, RMSE = 1.5359792224693134e-05\n",
      "k = 26, RMSE = 1.5287837625689158e-05\n",
      "k = 27, RMSE = 1.5299874037234285e-05\n",
      "k = 28, RMSE = 1.5286212292922813e-05\n",
      "k = 29, RMSE = 1.5254235603074766e-05\n",
      "k = 30, RMSE = 1.5208786883686418e-05\n",
      "\n",
      "Pencarian K selesai. K optimal ditemukan: 30\n",
      "Dengan nilai RMSE terendah: 1.5208786883686418e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMemulai pencarian K optimal...\")\n",
    "\n",
    "# Persiapan: Ubah y_test ke skala asli untuk perbandingan RMSE\n",
    "# Variabel target_scaler_z dan y_test sudah ada dari sel sebelumnya\n",
    "y_test_orig = target_scaler_z.inverse_transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "rmse_values = [] # Untuk menyimpan nilai RMSE\n",
    "range_k = range(1, 31) # Kita akan tes K dari 1 sampai 30\n",
    "\n",
    "# Loop untuk mencari K\n",
    "for k in range_k:\n",
    "    # 1. Latih model K-NN sementara\n",
    "    knn_model_tune = KNeighborsRegressor(n_neighbors=k, n_jobs=-1)\n",
    "    knn_model_tune.fit(X_train, y_train)\n",
    "    \n",
    "    # 2. Prediksi data test\n",
    "    y_pred_tune = knn_model_tune.predict(X_test)\n",
    "    \n",
    "    # 3. Kembalikan prediksi ke skala asli\n",
    "    y_pred_orig_tune = target_scaler_z.inverse_transform(y_pred_tune.reshape(-1, 1))\n",
    "    \n",
    "    # 4. Hitung RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig_tune))\n",
    "    \n",
    "    # 5. Simpan RMSE\n",
    "    rmse_values.append(rmse)\n",
    "    print(f\"k = {k}, RMSE = {rmse}\") # Cetak progres seperti di sel [40] Anda\n",
    "\n",
    "# Cari K Terbaik\n",
    "best_rmse_from_tuning = min(rmse_values)\n",
    "# +1 karena index list mulai dari 0, tapi K kita mulai dari 1\n",
    "best_k = rmse_values.index(best_rmse_from_tuning) + 1\n",
    "\n",
    "print(f\"\\nPencarian K selesai. K optimal ditemukan: {best_k}\")\n",
    "print(f\"Dengan nilai RMSE terendah: {best_rmse_from_tuning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9b8d04",
   "metadata": {},
   "source": [
    "### Pelatihan Model K-NN\n",
    "Cell ini menginisialisasi model K-NN Regressor dan melatihnya menggunakan data latih (X_train dan y_train). Proses .fit() adalah saat model mempelajari pola dari data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85503edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melatih model kNN optimal (K=30) dengan metrik 'euclidean'...\n",
      "Selesai! Model final disimpan dalam variabel 'knn_model'.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Training Model kNN Optimal ---\n",
    "# Menggunakan best_k yang ditemukan dari sel Hyperparameter Tuning\n",
    "print(f\"Melatih model kNN optimal (K={best_k}) dengan metrik 'euclidean'...\")\n",
    "\n",
    "# Inisialisasi dan latih model final\n",
    "# Kita tetap gunakan 'knn_model' agar sel [36] dan [37] tetap berfungsi\n",
    "knn_model = KNeighborsRegressor(\n",
    "    n_neighbors=best_k, \n",
    "    metric='euclidean',  # Modifikasi: sebutkan metrik secara eksplisit\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Latih model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Selesai! Model final disimpan dalam variabel 'knn_model'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140499a",
   "metadata": {},
   "source": [
    "### Pelaksanaan Prediksi\n",
    "Model yang telah dilatih digunakan untuk membuat prediksi pada data uji (X_test). Hasil prediksi dari model disimpan dalam variabel y_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6608565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selesai! Prediksi data test telah dibuat.\n",
      "Hasil prediksi disimpan dalam variabel 'y_pred'.\n",
      "\n",
      "Cuplikan 5 hasil prediksi pertama (y_pred):\n",
      "[-0.20825583  0.54852096 -0.48078236 -0.68209865 -0.2683705 ]\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# --- 5. Tampilkan Hasil ---\n",
    "print(\"\\nSelesai! Prediksi data test telah dibuat.\")\n",
    "print(\"Hasil prediksi disimpan dalam variabel 'y_pred'.\")\n",
    "print(\"\\nCuplikan 5 hasil prediksi pertama (y_pred):\")\n",
    "print(y_pred[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19136ced",
   "metadata": {},
   "source": [
    "### Evaluasi Model\n",
    "Cell ini bertujuan untuk mengukur performa model prediksi. Hasil prediksi (y_pred_orig) dibandingkan dengan data aktual (y_test_orig) menggunakan beberapa metrik evaluasi: MAE, MSE, dan RMSE, MAPE. Nilai metrik yang lebih rendah mengindikasikan tingkat akurasi model yang lebih tinggi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97902fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluasi Model Optimal (K=30) ---\n",
      "MAE:  0.0000093526\n",
      "MSE:  0.0000000002\n",
      "RMSE: 0.0000152088\n",
      "MAPE: 34.20%\n",
      "\n",
      "Kualitas Model: Cukup (MAPE > 20%)\n"
     ]
    }
   ],
   "source": [
    "# Import library baru untuk MAPE\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Mengembalikan nilai ke skala asli (unit NO2)\n",
    "# y_pred diambil dari sel [36]\n",
    "# y_test diambil dari sel [34]\n",
    "# target_scaler_z diambil dari sel [30]\n",
    "y_test_reshaped = y_test.values.reshape(-1, 1)\n",
    "y_pred_reshaped = y_pred.reshape(-1, 1)\n",
    "\n",
    "y_test_orig = target_scaler_z.inverse_transform(y_test_reshaped)\n",
    "y_pred_orig = target_scaler_z.inverse_transform(y_pred_reshaped)\n",
    "\n",
    "# Hitung Metrik Evaluasi\n",
    "mae = mean_absolute_error(y_test_orig, y_pred_orig)\n",
    "mse = mean_squared_error(y_test_orig, y_pred_orig)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test_orig, y_pred_orig) * 100 # MAPE BARU\n",
    "\n",
    "# --- TAMPILKAN OUTPUT ---\n",
    "# best_k diambil dari sel tuning yang baru Anda tambahkan\n",
    "print(f\"--- Evaluasi Model Optimal (K={best_k}) ---\")\n",
    "print(f\"MAE:  {mae:.10f}\")  # Format berbeda dari teman Anda\n",
    "print(f\"MSE:  {mse:.10f}\")\n",
    "print(f\"RMSE: {rmse:.10f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\") # Menambahkan MAPE\n",
    "\n",
    "# Menambahkan blok if/else\n",
    "if mape < 10:\n",
    "    print(\"\\nKualitas Model: Baik Sekali (MAPE < 10%)\")\n",
    "elif mape < 20:\n",
    "    print(\"\\nKualitas Model: Baik (MAPE 10-20%)\")\n",
    "else:\n",
    "    print(\"\\nKualitas Model: Cukup (MAPE > 20%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab560444",
   "metadata": {},
   "source": [
    "#### Klasifikasi Indikator Kualitas Udara\n",
    "\n",
    "Setelah model dievaluasi, kita dapat mengklasifikasikan nilai prediksi mentah (konsentrasi NO2) ke dalam kategori yang mudah dipahami (Sangat Rendah, Rendah, Sedang, Tinggi).\n",
    "\n",
    "Penting: *Threshold* (ambang batas) untuk kategori ini dihitung menggunakan kuartil (Q1, Q2, Q3) **hanya dari data latih (Train)**. Ini untuk mencegah *data leakage*, yaitu agar model uji (Test) tidak memengaruhi cara kita membuat kategori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b145e92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Membuat klasifikasi 4-kategori (berbasis kuartil data latih)...\n",
      "Thresholds (dari data latih): Q1 (Sangat Rendah) <= 0.000027, Q2 (Rendah) <= 0.000039, Q3 (Sedang) <= 0.000064\n",
      "\n",
      "Cuplikan 5 baris pertama hasil klasifikasi:\n",
      "     Tanggal    Aktual  Prediksi Kualitas Udara Aktual Kualitas Udara Prediksi\n",
      "0 2024-10-28  0.000073  0.000042                Tinggi                  Sedang\n",
      "1 2024-10-29  0.000014  0.000066         Sangat Rendah                  Tinggi\n",
      "2 2024-10-30  0.000008  0.000034         Sangat Rendah                  Rendah\n",
      "3 2024-10-31  0.000053  0.000027                Sedang                  Rendah\n",
      "4 2024-11-01  0.000034  0.000040                Rendah                  Sedang\n",
      "\n",
      "Hasil lengkap disimpan di 'hasil_prediksi_dan_klasifikasi.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"\\nMembuat klasifikasi 4-kategori (berbasis kuartil data latih)...\")\n",
    "\n",
    "# --- 1. Hitung Threshold Kuartil dari Data Latih ---\n",
    "# Variabel df_supervised (un-normalized) ada dari sel [29]\n",
    "# Variabel train_size (panjang data latih) ada dari sel [34]\n",
    "\n",
    "# Ambil data target (y) yang TIDAK ternormalisasi dari data latih\n",
    "train_data_orig_target = df_supervised['NO2_target(t)'].iloc[0:train_size]\n",
    "\n",
    "# Hitung threshold kuartil\n",
    "q1 = train_data_orig_target.quantile(0.25)\n",
    "q2_median = train_data_orig_target.quantile(0.50)\n",
    "q3 = train_data_orig_target.quantile(0.75)\n",
    "print(f\"Thresholds (dari data latih): Q1 (Sangat Rendah) <= {q1:.6f}, Q2 (Rendah) <= {q2_median:.6f}, Q3 (Sedang) <= {q3:.6f}\")\n",
    "\n",
    "# --- 2. Fungsi Klasifikasi ---\n",
    "def classify_air_quality(value, q1, q2, q3):\n",
    "    if value <= q1:\n",
    "        return \"Sangat Rendah\"\n",
    "    elif value <= q2:\n",
    "        return \"Rendah\"\n",
    "    elif value <= q3:\n",
    "        return \"Sedang\"\n",
    "    else:\n",
    "        return \"Tinggi\"\n",
    "\n",
    "# --- 3. Buat DataFrame Hasil ---\n",
    "# Variabel t_test, y_test_orig, dan y_pred_orig sudah ada dari sel-sel sebelumnya\n",
    "df_results = pd.DataFrame({\n",
    "    'Tanggal': t_test.reset_index(drop=True), # Reset index t_test agar sesuai\n",
    "    'Aktual': y_test_orig.flatten(),\n",
    "    'Prediksi': y_pred_orig.flatten() # Menggunakan y_pred_orig dari sel [37]\n",
    "})\n",
    "\n",
    "# --- 4. Terapkan Klasifikasi ---\n",
    "df_results['Kualitas Udara Aktual'] = df_results['Aktual'].apply(classify_air_quality, args=(q1, q2_median, q3))\n",
    "df_results['Kualitas Udara Prediksi'] = df_results['Prediksi'].apply(classify_air_quality, args=(q1, q2_median, q3))\n",
    "\n",
    "print(\"\\nCuplikan 5 baris pertama hasil klasifikasi:\")\n",
    "print(df_results.head())\n",
    "\n",
    "# Simpan ke CSV\n",
    "df_results.to_csv('./dataset/hasil_prediksi_dan_klasifikasi.csv', index=False)\n",
    "print(\"\\nHasil lengkap disimpan di 'hasil_prediksi_dan_klasifikasi.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tugaspsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}